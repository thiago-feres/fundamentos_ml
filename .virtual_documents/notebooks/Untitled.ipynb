


from sklearn import datasets as dt
from matplotlib import pyplot as plt
from sklearn import model_selection as ms
from sklearn import linear_model as lm
from sklearn import metrics as mt
import numpy as np





x, y = dt.make_classification(
    n_samples=100,
    n_features=2,
    n_informative=1,
    random_state=42,
    n_clusters_per_class=1,
    n_redundant=0
)



plt.scatter(x[:, 0], x[:, 1], c=y)


x_train, x_test, y_train, y_test = ms.train_test_split(x, y, test_size=0.3, random_state=42)


# define
model = lm.LogisticRegression()

# training
model.fit(x_train, y_train)

# performance
yhat_test = model.predict(x_test)
f1 = mt.f1_score(y_test, yhat_test)
print(f'f1 Score', f1)





yhat = theta_0 + theta_1 * x1 + theta_2 * x2


theta_0 = model.intercept_[0]
theta_1, theta_2 = model.coef_.T


c = -theta_0/theta_2
m = -theta_1/theta_2


xmin, xmax = -1.6, 2.7
ymin, ymax = -1.6, 3.0

xd = np.array([xmin, xmax])
yd = m*xd + c


plt.plot(xd, yd, 'k', lw=1, ls='--');
plt.fill_between(xd, yd, ymin, color='blue', alpha=0.2)
plt.fill_between(xd, yd, ymax, color='red', alpha=0.2)
plt.scatter(x[:, 0], x[:, 1], c=y)
plt.xlim(xmin, xmax)
plt.ylim(ymin, ymax)


np.min(x_train)





xx, yy = np.mgrid[-2:2.5:0.01, -2:3.0:0.01]
grid = np.c_[xx.ravel(), yy.ravel()]


probs = model.predict_proba(grid)[:, 1].reshape(xx.shape)


probs


f, ax = plt.subplots(figsize=(8,6))
contour = ax.contourf(xx, yy, probs, 9, cmap='RdBu', vmin=0, vmax=1)

ax_c = f.colorbar(contour)
ax_c.set_label('P(y=1)')

plt.scatter(x_train[:, 0], x_train[:, 1], c=y_train)
ax.set(
    aspect='equal',
    xlim=(-2, 2.5), 
    ylim=(-2,3),
    xlabel='x_1',
    ylabel='x_2'
)











